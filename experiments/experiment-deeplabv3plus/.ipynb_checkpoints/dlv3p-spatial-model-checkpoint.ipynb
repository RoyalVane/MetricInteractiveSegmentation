{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeptriplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptriplet.models.deeplabv3p.deeplab_spatial_last import DeepLabSpatialLate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 513, 513])\n"
     ]
    }
   ],
   "source": [
    "model = DeepLabSpatialLate(backbone='resnet', output_stride=16, dynamic_coordinates=False)\n",
    "model.eval().cuda()\n",
    "input = torch.rand(1, 3, 513, 513).cuda()\n",
    "output = model(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from modeling.sync_batchnorm.batchnorm import SynchronizedBatchNorm2d\n",
    "\n",
    "class DecoderSpatialLast(nn.Module):\n",
    "    def __init__(self, num_classes, backbone, BatchNorm, dynamic=False, size=(129, 129)):\n",
    "        super(DecoderSpatialLast, self).__init__()\n",
    "        if backbone == 'resnet' or backbone == 'drn':\n",
    "            low_level_inplanes = 256\n",
    "        elif backbone == 'xception':\n",
    "            low_level_inplanes = 128\n",
    "        elif backbone == 'mobilenet':\n",
    "            low_level_inplanes = 24\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        self.size = size\n",
    "        self.dynamic = dynamic\n",
    "\n",
    "        self.conv1 = nn.Conv2d(low_level_inplanes, 48, 1, bias=False)\n",
    "        self.bn1 = BatchNorm(48)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       BatchNorm(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(0.5),\n",
    "                                       nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       BatchNorm(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(0.1))\n",
    "        \n",
    "        self.conv_out = nn.Conv2d(258, num_classes, kernel_size=1, stride=1)\n",
    "        \n",
    "        x = np.linspace(-1., 1., self.size[1], dtype=np.float32)\n",
    "        y = np.linspace(-1., 1., self.size[0], dtype=np.float32)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "        spatial_channels = np.append(np.expand_dims(xx,axis=0), np.expand_dims(yy,axis=0), axis=0)\n",
    "        spatial_channels = np.expand_dims(spatial_channels, axis=0)\n",
    "\n",
    "        self.spatial_channels = torch.tensor(spatial_channels, device='cuda:0')\n",
    "    \n",
    "        self._init_weight()\n",
    "\n",
    "\n",
    "    def forward(self, x, low_level_feat):\n",
    "        low_level_feat = self.conv1(low_level_feat)\n",
    "        low_level_feat = self.bn1(low_level_feat)\n",
    "        low_level_feat = self.relu(low_level_feat)\n",
    "\n",
    "        x = F.interpolate(x, size=low_level_feat.size()[2:], mode='bilinear', align_corners=True)\n",
    "        x = torch.cat((x, low_level_feat), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        \n",
    "        if self.dynamic:\n",
    "            xc = np.linspace(-x.shape[3] / 129., x.shape[3] / 129., x.shape[3], dtype=np.float32)\n",
    "            yc = np.linspace(-x.shape[2] / 129., x.shape[2] / 129., x.shape[2], dtype=np.float32)\n",
    "            xx, yy = np.meshgrid(xc, yc)\n",
    "\n",
    "            spatial_channels = np.append(np.expand_dims(xx,axis=0), np.expand_dims(yy,axis=0), axis=0)\n",
    "            spatial_channels = np.expand_dims(spatial_channels, axis=0)\n",
    "\n",
    "            self.spatial_channels = torch.tensor(spatial_channels, device='cuda:0')\n",
    "            \n",
    "            x = torch.cat((x, self.spatial_channels), dim=1)\n",
    "            x = self.conv_out(x)\n",
    "        else:\n",
    "            x = torch.cat((x, self.spatial_channels), dim=1)\n",
    "            x = self.conv_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, SynchronizedBatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def build_decoder_spatial_last(num_classes, backbone, BatchNorm, dynamic=False, size=(129, 129)):\n",
    "    return DecoderSpatialLast(num_classes, backbone, BatchNorm, dynamic=dynamic, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 200, 513])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from modeling.sync_batchnorm.batchnorm import SynchronizedBatchNorm2d\n",
    "from modeling.aspp import build_aspp\n",
    "from modeling.backbone import build_backbone\n",
    "\n",
    "class DeepLabSpatialLate(nn.Module):\n",
    "    def __init__(self, backbone='resnet', output_stride=16, num_classes=21,\n",
    "                 sync_bn=True, freeze_bn=False, dynamic_coordinates=False, spatial_size=(129, 129)):\n",
    "        super(DeepLabSpatialLate, self).__init__()\n",
    "        if backbone == 'drn':\n",
    "            output_stride = 8\n",
    "\n",
    "        if sync_bn == True:\n",
    "            BatchNorm = SynchronizedBatchNorm2d\n",
    "        else:\n",
    "            BatchNorm = nn.BatchNorm2d\n",
    "\n",
    "        self.backbone = build_backbone(backbone, output_stride, BatchNorm)\n",
    "        self.aspp = build_aspp(backbone, output_stride, BatchNorm)\n",
    "        self.decoder = build_decoder_spatial_last(num_classes, backbone, BatchNorm, dynamic=dynamic_coordinates, size=spatial_size)\n",
    "\n",
    "        if freeze_bn:\n",
    "            self.freeze_bn()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x, low_level_feat = self.backbone(input)\n",
    "        x = self.aspp(x)\n",
    "        x = self.decoder(x, low_level_feat)\n",
    "        x = F.interpolate(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, SynchronizedBatchNorm2d):\n",
    "                m.eval()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def get_1x_lr_params(self):\n",
    "        modules = [self.backbone]\n",
    "        for i in range(len(modules)):\n",
    "            for m in modules[i].named_modules():\n",
    "                if isinstance(m[1], nn.Conv2d) or isinstance(m[1], SynchronizedBatchNorm2d) \\\n",
    "                        or isinstance(m[1], nn.BatchNorm2d):\n",
    "                    for p in m[1].parameters():\n",
    "                        if p.requires_grad:\n",
    "                            yield p\n",
    "\n",
    "    def get_10x_lr_params(self):\n",
    "        modules = [self.aspp, self.decoder]\n",
    "        for i in range(len(modules)):\n",
    "            for m in modules[i].named_modules():\n",
    "                if isinstance(m[1], nn.Conv2d) or isinstance(m[1], SynchronizedBatchNorm2d) \\\n",
    "                        or isinstance(m[1], nn.BatchNorm2d):\n",
    "                    for p in m[1].parameters():\n",
    "                        if p.requires_grad:\n",
    "                            yield p\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = DeepLabSpatialLate(backbone='resnet', output_stride=16, dynamic_coordinates=True)\n",
    "    model.eval().cuda()\n",
    "    input = torch.rand(1, 3, 200, 513).cuda()\n",
    "    output = model(input)\n",
    "    print(output.size())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
