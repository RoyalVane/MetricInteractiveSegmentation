{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import deeptriplet\n",
    "import deeptriplet.datasets\n",
    "import deeptriplet.triplet\n",
    "from deeptriplet.models.deeplabv3p import DeepLabSpatialEarly\n",
    "from deeptriplet.datasets import PascalMultiTriplet\n",
    "from deeptriplet.triplet import MultiTripletPreselected\n",
    "\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import math\n",
    "import random\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "\n",
    "trainset = deeptriplet.datasets.PascalDatasetRandomTripletAugmented(\n",
    "                        pascal_root=\"/scratch-second/yardima/datasets/VOC2012\",\n",
    "                        split_file=\"/home/yardima/Python/experiments/pascal_split/train_obj.txt\",\n",
    "                        n_triplets=500)\n",
    "\n",
    "trainloader = data.DataLoader(trainset,\n",
    "                                batch_size=8,\n",
    "                                num_workers=4,\n",
    "                                shuffle=True)\n",
    "\n",
    "net = DeepLabSpatialEarly(backbone='resnet', output_stride=16, num_classes=64, sync_bn=False, freeze_bn=False, dynamic_coordinates=False, pretrained=False)\n",
    "net = net.cuda()\n",
    "\n",
    "d = torch.load(\"/scratch-second/yardima/pretrained-models/deeplab-resnet-v3-plus.pth\")\n",
    "net.init_from_semseg_model(d)\n",
    "net = net.cuda()\n",
    "init_lr = 3e-4\n",
    "optimizer = optim.SGD([{'params': net.get_1x_lr_params(), 'lr': init_lr},\n",
    "                       {'params': net.get_10x_lr_params(), 'lr': init_lr * 10}],\n",
    "                      lr=init_lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss(ignore_index=255)\n",
    "loss_fn = deeptriplet.triplet.RandomTripletPreselected(n_batch=8, n_triplets=500)\n",
    "net = net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0755867958068848\n",
      "1.9772038459777832\n",
      "2.9934940338134766\n",
      "4.014428615570068\n",
      "4.535888671875\n",
      "3.2391197681427\n",
      "6.229218482971191\n",
      "3.4361634254455566\n",
      "3.332658529281616\n",
      "2.1183698177337646\n",
      "2.455063819885254\n",
      "1.511649489402771\n",
      "1.598556637763977\n",
      "1.7728849649429321\n",
      "1.3821467161178589\n",
      "1.3036298751831055\n",
      "1.504967212677002\n",
      "1.33651864528656\n",
      "1.291544795036316\n",
      "1.5299073457717896\n",
      "1.1572859287261963\n",
      "1.241246223449707\n",
      "1.1037187576293945\n",
      "0.8393304347991943\n",
      "1.1357799768447876\n",
      "1.062286138534546\n",
      "0.9933729767799377\n",
      "1.1239629983901978\n",
      "0.9717240333557129\n",
      "0.878770112991333\n",
      "1.158694863319397\n",
      "0.8220223784446716\n",
      "1.0184012651443481\n",
      "1.1250277757644653\n",
      "0.6477077603340149\n",
      "0.9476750493049622\n",
      "0.9854138493537903\n",
      "1.024397850036621\n",
      "1.0736340284347534\n",
      "0.8611063361167908\n",
      "0.8044372797012329\n",
      "0.6669158935546875\n",
      "0.6082229018211365\n",
      "0.7692926526069641\n",
      "0.9317765235900879\n",
      "0.6247314810752869\n",
      "0.7059388756752014\n",
      "0.7799034118652344\n",
      "0.9340869784355164\n",
      "1.072808861732483\n",
      "0.5462229251861572\n",
      "1.0621817111968994\n",
      "CPU times: user 29.8 s, sys: 15.4 s, total: 45.2 s\n",
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for ii, sample_batched in enumerate(trainloader):\n",
    "\n",
    "    inputs, labels = sample_batched\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = net.forward(inputs)\n",
    "    loss = loss_fn.compute_loss(outputs, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.item())\n",
    "\n",
    "    del loss, outputs\n",
    "    \n",
    "    if ii > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_labeled_image_list(data_dir, data_list):\n",
    "    \"\"\"Reads txt file containing paths to images and ground truth masks.\n",
    "\n",
    "    Args:\n",
    "      data_dir: path to the directory with images and masks.\n",
    "      data_list: path to the file with lines of the form '/path/to/image /path/to/mask'.\n",
    "\n",
    "    Returns:\n",
    "      Two lists with all file names for images and masks, respectively.\n",
    "    \"\"\"\n",
    "    f = open(data_list, 'r')\n",
    "    images = []\n",
    "    masks = []\n",
    "    for line in f:\n",
    "        image, mask = line.strip(\"\\n\").split(' ')\n",
    "        images.append(data_dir + image)\n",
    "        masks.append(data_dir + mask)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "class PascalMultiTriplet(data.Dataset):\n",
    "    \"\"\"Data loader for the Pascal VOC semantic segmentation dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            pascal_root,\n",
    "            split_file,\n",
    "            n_triplets,\n",
    "            samples_pos,\n",
    "            samples_neg\n",
    "    ):\n",
    "        self.split_file = split_file\n",
    "        self.pascal_root = pascal_root\n",
    "        self.n_triplets = n_triplets\n",
    "\n",
    "        self.n_classes = 21\n",
    "        \n",
    "        self.crop_size = 513\n",
    "        self.base_size = 513\n",
    "\n",
    "        self.image_list, self.label_list = read_labeled_image_list(self.pascal_root, self.split_file)\n",
    "\n",
    "        self.transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                   std=[0.229, 0.224, 0.225])])\n",
    "        \n",
    "        self.fill_image = (124, 116, 104)\n",
    "        self.fill_label = 255\n",
    "        \n",
    "        self.samples_pos = samples_pos\n",
    "        self.samples_neg = samples_neg\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im_path = self.image_list[index]\n",
    "        lbl_path = self.label_list[index]\n",
    "\n",
    "        img = PIL.Image.open(im_path)\n",
    "        lbl = PIL.Image.open(lbl_path)\n",
    "\n",
    "        ## augmentation\n",
    "        img, lbl = self._augment(img, lbl)\n",
    "\n",
    "        img, lbl = self._random_crop(img, lbl)\n",
    "        \n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        lbl = np.array(lbl, dtype=np.long)\n",
    "        #         lbl[lbl==255] = 0\n",
    "\n",
    "        img = self.transforms(img)\n",
    "        \n",
    "        minrange = [0, 0]\n",
    "        maxrange = [513, 513]\n",
    "        \n",
    "        triplets = self._generate_triplet(lbl)\n",
    "        \n",
    "\n",
    "        return (img, *triplets)\n",
    "    \n",
    "    \n",
    "    def _augment(self, img, lbl):\n",
    "        \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "            lbl = lbl.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "        if np.random.random() < 0.5:\n",
    "            img = img.filter(PIL.ImageFilter.GaussianBlur(\n",
    "                radius=random.random()))\n",
    "\n",
    "        \n",
    "        \n",
    "        return img, lbl\n",
    "\n",
    "    \n",
    "    def _random_crop(self, img, mask):\n",
    "        # random scale (short edge)\n",
    "        short_size = random.randint(int(self.base_size * 0.5), int(self.base_size * 2.0))\n",
    "        w, h = img.size\n",
    "        if h > w:\n",
    "            ow = short_size\n",
    "            oh = int(1.0 * h * ow / w)\n",
    "        else:\n",
    "            oh = short_size\n",
    "            ow = int(1.0 * w * oh / h)\n",
    "        img = img.resize((ow, oh), Image.BILINEAR)\n",
    "        mask = mask.resize((ow, oh), Image.NEAREST)\n",
    "        # pad crop\n",
    "        padh = self.crop_size - oh if oh < self.crop_size else 0\n",
    "        padw = self.crop_size - ow if ow < self.crop_size else 0\n",
    "        if short_size < self.crop_size:\n",
    "            img = ImageOps.expand(img, border=(padw//2 + 1, padh//2 + 1, padw//2 + 1, padh//2 + 1), fill=self.fill_image)\n",
    "            mask = ImageOps.expand(mask, border=(padw//2 + 1, padh//2 + 1, padw//2 + 1, padh//2 + 1), fill=self.fill_label)\n",
    "        # random crop crop_size\n",
    "        w, h = img.size\n",
    "        x1 = random.randint(0, w - self.crop_size)\n",
    "        y1 = random.randint(0, h - self.crop_size)\n",
    "        img = img.crop((x1, y1, x1 + self.crop_size, y1 + self.crop_size))\n",
    "        mask = mask.crop((x1, y1, x1 + self.crop_size, y1 + self.crop_size))\n",
    "\n",
    "        ## TODO: unnecessary code\n",
    "#         minrange = [max(x1 - padw//2 - 1, 0), max(y1 - padh//2 - 1, 0)]\n",
    "#         maxrange = [min(x1 + 2 * self.crop_size - padw//2 - 1 - w, self.crop_size - 1), \n",
    "#                     min(y1 + 2 * self.crop_size - padh//2 - 1 - h, self.crop_size - 1)]\n",
    "        \n",
    "        return img, mask # , minrange, maxrange\n",
    "    \n",
    "\n",
    "    def _generate_triplet(self, lbl):\n",
    "        lbl_view = lbl[0:513, 0:513]\n",
    "        \n",
    "        options = np.nonzero(lbl_view.reshape(-1) != 255)[0]\n",
    "        \n",
    "        if options.shape[0] > 0:\n",
    "            ai = np.random.randint(low=0, \n",
    "                                    high=options.shape[0], \n",
    "                                    size=(self.n_triplets,))\n",
    "            ai = options[ai]\n",
    "        else:\n",
    "            ai = np.array([0] * self.n_triplets, dtype=np.int64)\n",
    "        \n",
    "\n",
    "        classes, inv_map = np.unique(lbl_view, return_inverse=True)\n",
    "        n_classes = len(classes)\n",
    "        inv_map = inv_map.reshape(lbl_view.shape[0], lbl_view.shape[1])\n",
    "        inv_map_flat = inv_map.reshape(-1)\n",
    "\n",
    "        class_lookup = (np.arange(n_classes, dtype=np.int32).reshape((1, 1, n_classes)) !=\n",
    "                        inv_map.reshape(lbl_view.shape[0], lbl_view.shape[1], 1))\n",
    "        class_lookup = np.transpose(class_lookup, axes=[2, 0, 1])\n",
    "        \n",
    "        lbl_view_flat = lbl_view.reshape(-1)\n",
    "        \n",
    "        lneg = []\n",
    "        lpos = []\n",
    "        for i in range(n_classes):\n",
    "            lneg.append(np.transpose(np.logical_and(lbl_view != 255, class_lookup[i]).reshape(-1).nonzero()).reshape((-1)))\n",
    "            lpos.append(np.transpose(\n",
    "                                np.logical_and(lbl_view != 255, \n",
    "                                               np.logical_not(class_lookup[i])).reshape(-1).nonzero()).reshape((-1)))\n",
    "            \n",
    "        ni, pi = [], []\n",
    "        for i in range(self.n_triplets):\n",
    "            cni = lneg[inv_map_flat[ai[i]]][lneg[inv_map_flat[ai[i]]] != ai[i]] \n",
    "            cpi = lpos[inv_map_flat[ai[i]]][lpos[inv_map_flat[ai[i]]] != ai[i]]\n",
    "            \n",
    "            for _ in range(self.samples_pos):\n",
    "                if len(cni) == 0 or len(cpi) == 0:\n",
    "                    #ni.append(ai[i])\n",
    "                    pi.append(ai[i])\n",
    "                else:\n",
    "                    #ni.append( np.random.choice(cni))\n",
    "                    pi.append( np.random.choice(cpi))\n",
    "                    \n",
    "            for _ in range(self.samples_neg):\n",
    "                if len(cni) == 0 or len(cpi) == 0:\n",
    "                    ni.append(ai[i])\n",
    "                    #pi.append(ai[i])\n",
    "                else:\n",
    "                    ni.append( np.random.choice(cni))\n",
    "                    #pi.append( np.random.choice(cpi))\n",
    "            \n",
    "        #aix, aiy = np.unravel_index(ai, dims=(lbl_view.shape[0], lbl_view.shape[1]))\n",
    "        #aix += minrange[0]\n",
    "        #aiy += minrange[1]\n",
    "        #ai = np.stack((aix, aiy))\n",
    "        \n",
    "        #pix, piy = np.unravel_index(pi, dims=(lbl_view.shape[0], lbl_view.shape[1]))\n",
    "        #pix += minrange[0]\n",
    "        #piy += minrange[1]\n",
    "        #pi = np.stack((pix, piy))\n",
    "        \n",
    "        #nix, niy = np.unravel_index(ni, dims=(lbl_view.shape[0], lbl_view.shape[1]))\n",
    "        #nix += minrange[0]\n",
    "        #niy += minrange[1]\n",
    "        #ni = np.stack((nix, niy))\n",
    "        \n",
    "        #triplets = np.stack((ai, pi, ni), axis=0)\n",
    "        pi =  np.array(pi, dtype=np.int64)\n",
    "        ni =  np.array(ni, dtype=np.int64)\n",
    "        \n",
    "        ai = torch.tensor(ai.reshape(self.n_triplets), dtype=torch.long)\n",
    "        pi = torch.tensor(pi.reshape(-1, self.samples_pos), dtype=torch.long)\n",
    "        ni = torch.tensor(ni.reshape(-1, self.samples_neg), dtype=torch.long)\n",
    "        \n",
    "        return ai, pi, ni\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class MultiTripletPreselected:\n",
    "\n",
    "    def __init__(self, n_batch, margin=1, l2_penalty=1e-3):\n",
    "        self.margin = margin\n",
    "        self.l2_penalty = l2_penalty\n",
    "        self.n_batch = n_batch\n",
    "\n",
    "        self.loss_fun = nn.MarginRankingLoss(margin=margin)\n",
    "        self.target = torch.FloatTensor(3 * n_batch).fill_(1).cuda()\n",
    "        \n",
    "        i = 0\n",
    "        self.dim0a = []\n",
    "        self.dim0p = []\n",
    "        self.dim0n = []\n",
    "        for i in range(8):\n",
    "            self.dim0a += 3 * [i]\n",
    "            self.dim0p += 3 * [i]\n",
    "            self.dim0n += 3 * [i]\n",
    "            \n",
    "        self.dim0a = torch.from_numpy(np.array(self.dim0a, dtype=np.long)).cuda()\n",
    "        self.dim0p = torch.from_numpy(np.array(self.dim0p, dtype=np.long)).cuda()\n",
    "        self.dim0n = torch.from_numpy(np.array(self.dim0n, dtype=np.long)).cuda()\n",
    "\n",
    "    def compute_loss(self, output, a, p, n):\n",
    "\n",
    "        if len(self.dim0a) != a.shape[0] * a.shape[1] or \\\n",
    "            len(self.dim0p) != p.shape[0] * p.shape[1] * p.shape[2] or \\\n",
    "            len(self.dim0n) != n.shape[0] * n.shape[1] * n.shape[2]:\n",
    "            \n",
    "            self.dim0a = []\n",
    "            self.dim0p = []\n",
    "            self.dim0n = []\n",
    "            for i in range(a.shape[0]):\n",
    "                self.dim0a += a.shape[1] * [i]\n",
    "                self.dim0p += p.shape[1] * p.shape[2] * [i]\n",
    "                self.dim0n += n.shape[1] * n.shape[2] * [i]\n",
    "            \n",
    "            self.dim0a = torch.from_numpy(np.array(self.dim0a, dtype=np.long)).cuda()\n",
    "            self.dim0p = torch.from_numpy(np.array(self.dim0p, dtype=np.long)).cuda()\n",
    "            self.dim0n = torch.from_numpy(np.array(self.dim0n, dtype=np.long)).cuda()\n",
    "            \n",
    "            self.target = torch.FloatTensor(a.shape[0] * a.shape[1]).fill_(1).cuda()\n",
    "        \n",
    "        \n",
    "        n_dim = output.shape[1]\n",
    "        \n",
    "        out = output.view(output.shape[0], output.shape[1], -1)\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        \n",
    "        # compute distances\n",
    "        v_anch = out[self.dim0a, a.view(-1), :].view(-1, 1, n_dim)\n",
    "        v_pos = out[self.dim0p, p.view(-1), :].view(-1, p.shape[2], n_dim)\n",
    "        v_neg = out[self.dim0n, n.view(-1), :].view(-1, n.shape[2], n_dim)\n",
    "        \n",
    "        l2_norm = v_anch.pow(2).view(-1, n_dim).sum(dim=1).mean()\n",
    "        \n",
    "        delta_p = (v_anch - v_pos).pow(2).sum(dim=2)\n",
    "        delta_n = (v_anch - v_neg).pow(2).sum(dim=2)\n",
    "\n",
    "        delta_p, _ = delta_p.min(dim=1)\n",
    "        delta_n, _ = delta_n.min(dim=1)\n",
    "\n",
    "        loss = self.loss_fun(delta_n, delta_p, self.target) + l2_norm * self.l2_penalty\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3335983753204346\n",
      "1.1757022142410278\n",
      "0.7121611833572388\n",
      "0.8790137767791748\n",
      "1.003315806388855\n",
      "0.8870450854301453\n",
      "0.8245775103569031\n",
      "0.8456610441207886\n",
      "0.8013911843299866\n",
      "0.6996610760688782\n",
      "0.77012038230896\n",
      "0.604715883731842\n",
      "0.8514495491981506\n",
      "0.5517140030860901\n",
      "0.47690239548683167\n",
      "0.32431161403656006\n",
      "0.49633651971817017\n",
      "0.4512006938457489\n",
      "0.5363562107086182\n",
      "0.6377290487289429\n",
      "0.3827652335166931\n",
      "0.33467555046081543\n",
      "0.5080620050430298\n",
      "0.6009445190429688\n",
      "0.436949223279953\n",
      "0.26253804564476013\n",
      "0.30369994044303894\n",
      "0.37332314252853394\n",
      "0.26764845848083496\n",
      "0.39763572812080383\n",
      "0.2205560803413391\n",
      "0.32096898555755615\n",
      "0.3608282804489136\n",
      "0.567032516002655\n",
      "0.27135270833969116\n",
      "0.3811478614807129\n",
      "0.3406652808189392\n",
      "0.29958972334861755\n",
      "0.2797240614891052\n",
      "0.3896382451057434\n",
      "0.2775852382183075\n",
      "0.3833032548427582\n",
      "0.23668907582759857\n",
      "0.5160719156265259\n",
      "0.3370261788368225\n",
      "0.1922895461320877\n",
      "0.23706595599651337\n",
      "0.195984348654747\n",
      "0.22637256979942322\n",
      "0.26917076110839844\n",
      "0.22303369641304016\n",
      "0.35435861349105835\n",
      "CPU times: user 29.4 s, sys: 15.6 s, total: 45 s\n",
      "Wall time: 55.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainset = PascalMultiTriplet(\n",
    "                        pascal_root=\"/scratch-second/yardima/datasets/VOC2012\",\n",
    "                        split_file=\"/home/yardima/Python/experiments/pascal_split/train_obj.txt\",\n",
    "                        n_triplets=500,\n",
    "                        samples_neg=20,\n",
    "                        samples_pos=10)\n",
    "\n",
    "trainloader = data.DataLoader(trainset,\n",
    "                                batch_size=8,\n",
    "                                num_workers=4,\n",
    "                                shuffle=True)\n",
    "\n",
    "loss_fn = MultiTripletPreselected(n_batch=8)\n",
    "\n",
    "for ii, sample_batched in enumerate(trainloader):\n",
    "\n",
    "    inputs, a,p,n = sample_batched\n",
    "    inputs = inputs.cuda()\n",
    "    a = a.cuda()\n",
    "    p = p.cuda()\n",
    "    n = n.cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = net.forward(inputs)\n",
    "    loss = loss_fn.compute_loss(outputs, a, p, n)\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.item())\n",
    "\n",
    "    del loss,inputs,a,p,n,outputs\n",
    "    \n",
    "    if ii > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, a, p, n = trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 20])\n"
     ]
    }
   ],
   "source": [
    "print(n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
